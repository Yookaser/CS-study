# 운영체제

[[_TOC_]]

## 1. 운영체제

### 운영체제[개요]

#### 운영체제

- 사용자에게 편리한 인터페이스 환경을 제공하고 컴퓨터 시스템의 자원을 효율적으로 관리하는 소프트웨어입니다. 사용자와 하드웨어 간의 인터페이스로서 동작하는 시스템 소프트웨어의 일종으로, 다른 응용 프로그램이 작업할 수 있도록 환경을 제공합니다.



#### 운영체제의 역할과 목적

- 운영체제의 역할과 목표는 효율적인 자원 관리, 안정적인 자원 보호, 확장성 있는 하드웨어 인터페이스 제공(플러그 앤 플레이), 편리한 사용자 인터페이스 제공 등이 있습니다.



#### 운영체제의 성능평가 기준

- 처리능력, 반환시간, 사용가능도, 신뢰도가 있습니다.
  - 처리능력(Throughput): 일정 시간 내에 시스템이 처리하는 일의 양
  - 반환시간(Turn Around Time): 시스템에 작업을 의뢰한 시간부터 처리가 완료될 때까지 걸린 시간
  - 사용가능도(Availability): 시스템을 사용할 필요가 있을 때 즉시 사용 가능한 정도
  - 신뢰도(Reliabilty): 시스템이 주어진 문제를 정확하게 해결하는 정도



#### 운영체제의 기능

| 기능          | 자원                                                         |
| ------------- | ------------------------------------------------------------ |
| 프로세스 관리 | 1. 프로세스 스케줄링 및 동기화 관리<br />2. 프로세스 생성과 제거, 시작과 정지, 메시지 전달 등 |
| 기억장치 관리 | 프로세스에게 메모리 할당 및 회수 관리                        |
| 주변장치 관리 | 입출력 장치 스케줄링 및 전반적인 관리                        |
| 파일 관리     | 파일의 생성과 삭제, 변경, 유지 등                            |



#### 이중 모드

- 사용자 프로세스가 실행되는 사용자 모드와 커널 프로세스가 실행되는 커널 모드로 분리한 것으로 운영체제의 자원을 보호하기 위한 기법입니다. 사용자 프로세스가 하드디스크 입출력, 프로세스 생성과 같이 커널의 기능을 이용하기 위해서는 시스템 호출을 이용하여 커널 프로세스에 작업을 요청해야 합니다. 이처럼 운영체제가 두 모드를 전환하며 일처리를 하는 것을 이중 모드라고 합니다.
  - 사용자가 커널 모드로 진입하는 경우
    1. 시스템 호출을 사용하여 자발적으로 진입하는 경우
    2. 인터럽트가 발생하여 비자발적으로 진입하는 경우
       - 잘못된 명령을 수행하여 동기적 인터럽트가 발생한 것이므로 프로세스가 강제 종료됨

<hr>



### 커널

#### 커널(Kernel)

- 프로세스 관리, 메모리 관리, 저장장치 관리 같은 운영체제의 핵심적인 기능을 모아놓은 것으로 좁은 의미의 운영체제라고도 합니다. 운영체제도 소프트웨어이기에 메모리에 올라가야하는데 모두 올라간다면 메모리 공간의 낭비가 심하기 때문에 항상 필요한 부분만 올라가게됩니다. 이때 메모리에 상주하는 운영체제의 부분이 커널입니다.
  - 커널은 시스템 호출을 통해 응용 프로그램과 드라이버를 통해 하드웨어와 통신함



#### 커널의 기능

| 핵심 기능             | 설명                                                         |
| --------------------- | ------------------------------------------------------------ |
| 프로세스 관리         | 프로세스에 CPU를 배분하고 작업에 필요한 제반 환경을 제공     |
| 메모리 관리           | 프로세스에 작업 공간을 배치하고 실제 메모리보다 큰 가상공간을 제공 |
| 파일 시스템 관리      | 데이터를 저장하고 접근할 수 있는 인터페이스 제공             |
| 입출력 관리           | 필요한 입력과 출력 서비스를 제공                             |
| 프로세스 간 통신 관리 | 공동 작업을 위한 각 프로세스 간 통신 환경을 지원             |



#### 단일형 구조 커널 & 계층형 구조 커널

- 단일형 구조 커널: 커널의 핵심 기능을 구현하는 모듈들이 구분 없이 하나로 구성되는 커널로 초창기의 운영체제 구조입니다.

  - 모듈 간 통신 비용이 줄어들어 효율적인 운영이 가능

  - 모든 모듈이 하나로 묶여 있기 때문에 버그나 오류 처리가 어려움
  - 상호 의존성이 높아 작은 결함이 시스템 전체로 확산될 수 있음
  - 다양한 환경의 시스템에 적용하기 어려움
  - 현대 운영체제는 매우 크기 때문에 단일형으로 구현하기 어려움



- 계층형 구조 커널: 비슷한 기능을 가진 모듈을 묶어 하나의 계층을 만들고 계층 간 통신을 통해 운영체제를 구현하는 방식으로 대부분의 현대의 운영체제는 이 구조를 따릅니다.
  - 단일형보다 버그나 오류를 쉽게 처리할 수 있음
  - 오류 발생시 해당 계층만 따로 수정 가능하므로 디버깅 수월함

<hr>



### 인터럽트

#### 인터럽트

- CPU가 특정 기능을 수행하는 도중에 급하게 다른 일을 처리하고자 할 때 사용할 수 있는 기능입니다.



#### 인터럽트의 동작 과정

1. 기존의 작업 도중 인터럽트가 발생
2. 실행 중인 프로세스는 일시 정지 상태가 되며, 재시작하기 위해 관련 정보를 저장
3. 인터럽트 컨트롤러가 실행되어 인터럽트의 처리 순서를 결정
   - 만약 여러 인터럽트가 동시에 발생했다면 우선순위를 고려하여 중요 인터럽트부터 처리하도록 순서를 결정
4. 인터럽트 벡터에 등록된 인터럽트 핸들러가 실행
5. 인터럽트 핸들러가 처리를 마치면 일시 정지된 프로세스가 다시 실행되거나 종료
   - 입출력 같은 경우면 다시 실행되고, 메모리 영역 침범이나 오류면 종료



#### 인터럽트의 종류

| 종류          | 특징                                | 비고                         |
| ------------- | ----------------------------------- | ---------------------------- |
| 외부 인터럽트 | 입출력 및 하드웨어 관련 인터럽트    | 주변장치 변화, 하드웨어 이상 |
| 내부 인터럽트 | 프로세스의 오류로 발생하는 인터럽트 | 예외 상황 인터럽트           |
| 시그널        | 사용자 요청으로 발생하는 인터럽트   | 자발적 인터럽트              |



#### 인터럽트 번호(IRQ; Interrupt ReQuest)

- 여러 주변장치 중 어떤 것의 작업이 끝났는지 CPU에 알려주기 위해 사용하는 번호입니다. 즉 인터럽트 완료 신호를 보낼 떄 장치 이름 대신 사용하는 고유 번호로 운영체제마다 다릅니다.
  - 이는 인터럽트 번호와는 다름(단지 하드웨어의 각 장치를 구분하기 위해 붙인 번호)



#### 인터럽트 벡터(Interrupt Vector)

- 인터럽트가 발생했을 때, 그 인터럽트를 처리할 수 있는 서비스 루틴(ISR)들의 주소를 가진 공간입니다. 즉 인터럽트와 ISR(or 인터럽트 핸들러)와 일대일로 연결한 자료 구조입니다.



#### 동기적(Synchronous) 인터럽트와 비동기적(Asynchronous) 인터럽트

- 동기적 인터럽트는 CPU가 명령어를 실행하는 도중에 발생하는데, 실행중인 명령어의 실행을 마친 뒤에 발생시킵니다. 에러나 커널이 처리해야 하는 비정상적인 상황에 CPU가 대처하기 위한 작업들입니다.
- 비동기적 인터럽트는 실행중인 명령어와는 무관하게 입출력장치에 의한 경우와 같이 돌발적인 상황이 발생하는 인터럽트입니다.

<hr>



### 시스템 호출 | 드라이버 | 가상머신

#### 시스템 호출(System Call)

- 운영체제의 커널이 제공하는 서비스에 대해, 응용 프로그램의 요청에 따라 커널에 접근하기 위한 인터페이스입니다. 이러한 시스템 호출은 커널이 자신을 보호하기 위해 만든 인터페이스입니다.

  - 시스템 호출의 유형

    1. 프로세서 제어(process Control)
    2. 파일 조작(file manipulation)
    3.  장치 관리(Device Management)
    4. 정보 유지(Information maintenance)

    5. 통신(Communication)



#### 드라이버

- 하드웨어에서 커널에 접근하기 위한 인터페이스입니다. 시스템 호출과는 다르게 모든 하드웨어에 대한 인터페이스를 개발할 수 없으므로 커널이 제공하는 드라이버와 하드웨어 제작자가 제공하는 드라이버로 나뉘게됩니다. 즉 하드웨어는 커널과 직접 연결되기도 하고 하드웨어 제작자가 제공하는 드라이버를 통해 연결되기도 합니다.



#### 가상 머신(VM; Virtual Machin)

- 일반적으로 물리적인 하드웨어 시스템에 구축되어 자체 CPU, 메모리, 스토리지 등을 갖추고 컴퓨터 시스템으로 작동하는 가상 환경입니다. 즉 컴퓨터 안에 가상의 또 다른 컴퓨터들을 동작시키는 것을 의미합니다. 이러한 가상 머신은 시스템 가상 머신과 프로세스 가상 머신 두 가지로 나뉩니다.
  - 시스템 가상 머신: CPU, 메모리, 스토리지 등 모든 자원을 가상화하여 전체 운영체제를 실행하도록 설계된 것을 말합니다. 일반적으로 이런 가상 컴퓨터 하이퍼바이저 위에서 동작합니다. 
  - 프로세스 가상 머신: 플랫폼에 독립적인 실행 환경과 추상화를 제공하여 하나의 단일 프로그램을 실행하도록 설계된 것을 말합니다. 대표적으로 JVM이 있습니다.
  - 하이퍼바이저: 가상 머신을 생성하고 구동하는 소프트웨어입니다. 메모리 및 처리와 같은 단일 호스트 컴퓨터의 리소스를 가상으로 공유하여 호스트 컴퓨터가 여러 게스트 가상 머신을 지원할 수 있도록 합니다.(즉 운영체제와 가상 머신의 리소스를 분리하여 가상 머신의 생성과 관리를 지원)

<hr>



### 기타

#### 폰노이만 구조

- CPU, 메모리, 입출력장치, 저장장치가 버스로 연결되어 있는 구조로 오늘날 대부분의 컴퓨터가 따르는 구조입니다. 하드웨어는 그대로 둔 채 작업을 위한 프로그래만 교체하여 메모리에 올리는 방식으로 "모든 프로그램은 메모리에 올라와야 실행할 수 있다."라는 특징을 가집니다.
  - 시스템 버스: 메모리와 주변장치를 연결하는 버스로 전면 버스(FSB; Front-side Bust)라고 합니다.
  - CPU 내부 버스: CPU 내부에 있는 장치를 연결하는 버스로 후면 버스(BSF; Back-side Bust)라고 합니다. 시스템 버스보다 훨씬 빠른 속도로 동작합니다.





## 2. CPU

### CPU 개요

#### CPU의 구성

- 제어장치(CU; Control Unit): 전체 시스템의 작동을 통제 및 지시하는 장치로, 적절한 순서로 명령을 꺼내고, 각 명령을 읽고 해독하여 연산장치나 기타 부분으로 적절한 신호를 보내는 장치
  - 구성요소
    - 프로그램 카운터(Program Counter): 다음 수행할 명령어의 주소를 기억하는 레지스터
    - 명령 해독기(Instruction Decoder): 수행해야 할 명령어를 해석하여 부호기로 전달하는 회로
    - 부호기(Encoder): 명령 해독기에서 전송된 명령어를 필요한 신호로 변환하는 회로
    - 명령 레지스터(IR; Instruction Resister): 현재 수행 중인 명령어를 기억하는 레지스터
    - 주소 해독기(Adress Decoder): IR로부터 보내온 주소를 해석하는 회로
    - 메모리 주소 레지스터(MAR; Memory Address Resister): 메모리 관리자가 접근해야 할 메모리 주소를 저장(가져오거나 보내는)
    - 메모리 버퍼 레지스터(MBR; Memory Buffer Resister): 메모리 관리자가 가져온 데이터를 임시로 저장(항상 MAR과 함께 동작함)



- 산술논리 연산장치(ALU; Arithmetic and Logical Unit): 명령어를 실행하기 위한 마이크로 연산을 수행하는 장치
  - 구성요소
    - 가산기(Adder): 2진수 덧셈을 수행하는 회로
    - 보수기(Complementer): 뺄셈을 수행하기 위해 입력된 값을 보수로 변환하는 회로
    - 누산기(Accumulator): 중간 연산 결과를 일시적으로 기억하는 레지스터
    - 데이터 레지스터(DR; Data Resister): 연산한 데이터를 임시로 기억하는 레지스터
    - 프로그램 상태 워드(PSW; Program Status Word): 명령어 실행 중에 발생하는 CPU 상태 정보를 저장하는 상태 레지스터
    - 인덱스 레지스터(Index Resister): 유효 주소를 상대적으로 계산할 때 사용하는 레지스터
    - 베이스 레지스터(Base Resister): 유효 주소를 절대적으로 계산할 때 사용하는 레지스터



- 레지스터(Resister): CPU 내에 데이터를 임시로 보관하는 곳

<hr>



### 프로세스[개요]

#### 프로세스

- 프로세스: 메모리에 올라와 실행되고 있는 프로그램의 인스턴스
  - 운영체제로부터 독립된 메모리 영역을 할당받음(다른 프로세스의 자원에 접근 X)
  - 프로세스들은 독립적이기 때문에 통신하기 위해 프로세스 간 통신(IPC; Inter Process Communication)을 사용해야함(멀티태스크)
  - 프로세스는 최소 1개의 스레드를 가짐



#### 프로세스의 구조

- 코드(텍스트) 영역: 프로그램의 코드들이 저장되는 공간으로 읽기 전용으로 처리
- 데이터 영역: 전역 변수, 정적 변수, 구조체 등이 저장되는 영역으로 기본적으로 읽기와 쓰기가 가능(단, 상수 처리된 변수는 읽기 전용)
- 힙 영역: 프로그래머가 직접 관리할 수 있는 메모리 영역으로 이 공간에 메모리를 할당하는 것을 동적 할당이라고 부릅니다.
- 스택 영역: 함수의 호출과 함께 할당되며 지역 변수와 매개 변수가 저장되는 영역입니다. 저장되는 함수의 호출 정보를 스택프레임이라고 하며 사용자에게는 보이지 않는 영역입니다.



#### 프로세스와 프로그램

- 프로그램이 PCB를 얻으면 프로세스가 됩니다. 그리고 프로세스가 종료된다는 것은 프로세스 제어 블록이 폐기되어 프로그램이 된다는 것을 의미합니다.



#### 프로세스 제어 블록(PCB; Process Control Block)

- 특정한 프로세스를 관리하는데 필요한 정보가 있는 운영체제 커널의 자료 구조입니다. 중요한 정보가 있기 때문에, 일반 사용자가 접근하지 못하도록 보호된 메모리 영역에 존재합니다.



#### 프로세스 제어 블록의 구성

1. 포인터: PCB를 연결하여 준비 상태나 대기 상태의 큐를 구현할 때 사용
2. 프로세스 상태(Process State): 생성, 준비, 실행, 대기, 완료 상태 정보를 저장
3. 프로세스 식별자(PID; Process ID): 프로세스를 구분하기 위한 구분자
4. 프로그램 카운터: 프로그램 카운터의 값을 저장
5. 프로세스 우선순위: 프로세스의 우선순위를 저장
6. 각종 레지스터 정보: 프로세스가 실행 중 사용하던 레지스터의 값이 저장
7. 메모리 관리 정보: 해당 프로세스의 주소 정보, 경계 및 한계 레지스터 등을 저장
8. 할당 자원 정보: 프로세스 실행을 위한 입출력 자원이나 오픈 파일 등의 정보 저장
9. 부모 프로세스 구분자(PPID; Parent PID)와 자식 프로세스 구분자(CPID; Child PID)



#### 프로세스의 상태

- 생성 상태(Create Status): 프로그램을 메모리에 가져와 실행 준비가 완료된 상태
- 준비 상태(Ready Status): 실행을 기다리는 모든 프로세스가 자기 차례를 기다리는 상태로, 실행될 프로세스를 CPU 스케줄러가 선택
- 실행 상태(Running Status): 선택된 프로세스가 타임 슬라이스를 얻어 CPU를 사용하는 상태로, 프로세스 사이에 문맥 교환이 일어남
- 대기 상태(Blocking Status): 실행 상태에 있는 프로세스가 입출력을 요청하면 입출력이 완료될 때까지 기다리는 상태로, 입출력이 완료되면 준비 상태로 돌아감
- 완료 상태(Terminate Status): 프로세스가 종료된 상태로, 사용하던 모든 데이터가 정리된다. 정상 종료인 `exit()`와 `abort()`를 모두 포함
- 휴식 상태(Pause Status): 프로세스가 작업을 일시적으로 쉬고 있는 상태로, 사용하던 데이터가 메모리에 그대로 있고 PCB도 유지되므로 멈춤 시점붜 재시작할 수 있음
- 보류 상태(Suspend Status): 프로세스가 메모리에서 쫓겨난 상태로, 메모리에서 쫓겨난 데이터가 임시로 보관되는 곳인 스왑 영역에 보관됩니다. 보류 상태는 보류 대기 상태(대기 상태에서 옮겨짐)와 보류 준비 상태(준비 상태에서 옮겨짐)로 구분되며, 재시작하면 원래의 활성 상태로 들어갑니다. 또한 보류 대기 상태에서 입출력이 완료되면 보류 준비 상태로 옮겨갑니다.



#### 문맥 교환(Context Switching)

- 인터럽트를 발생시켜 CPU에서 실행중인 프로세스를 중단하고, 다른 프로세스를 처리하기 위한 과정입니다. 실행중인 프로세스의 상태(Context)를 PCB에 저장하고, 다음 프로세스의 PCB 내용으로 CPU를 다시 세팅하는 것을 의미합니다.



#### fork()와 exec()

- `fork()`는 실행 중인 새로운 프로세스를 복사하는 시스템 호출입니다. PCB의 PID, PPID, CPID, 메모리 관련 정보를 제외하고는 복사됩니다. 새로운 프로세스를 실행하는 것보다 기존의 프로세스를 복사하는 것이 훨씬 빠릅니다. 또한 부모 프로세스를 추가 자원없이 상속할 수 있으며, 이런 부모자식의 계층 관계를 통해 시스템을 효율적으로 관리할 수 있습니다.
- `exec()`는 프로세스는 그대로 둔 채 내용만 바꾸는 시스템 호출입니다. 이미 만들어진 프로세스의 구조를 재활용하기 위해 사용합니다.



#### 프로세스 계층 구조의 장점

- 여러 작업을 동시에 처리할 수 있고, 자원의 회수가 용이해집니다.



#### 고아 프로세스(Orphan Process)와 좀비 프로세스(Zombie Process)

- 고아 프로세스는 부모가 먼저 종료된  자식을 말합니다. 좀비 프로세스는 자식이 종료되었지만 부모 가 `wait()`를 통해 보고받지 못했을 때, 해당 자식 프로세스를 의미합니다.



#### 전면 프로세스와 후면 프로세스

- 전면 프로세스는 GUI를 사용하는 운영체제에서 화면의 맨 앞에 놓인 프로세스를 의미합니다. 즉 현재 입출력을 사용하는 프로세스이며, 사용자와 상호작용이 가능한 프로세스입니다. 후면 프로세스는 사용자와 상호작용이 없는 프로세스를 의미합니다.



#### CPU 집중 프로세스와 입출력 집중 프로세스

- CPU 집중 프로세스는 수학 연산과 같이 CPU를 많이 사용하는 프로세스를 말합니다. 입출력 집중 프로세스는 저장장치에서 데이터를 복사하는 일과 같이 입출력을 많이 사용하는 프로세스를 말합니다. 일반적으로 입출력 집중 프로세스가 더 먼저 처리됩니다.

<hr>



### 프로세스[통신]

#### 프로세스 간 통신의 종류

1. 프로세스 내부 데이터 통신: 한 프로세스 내에 2개 이상의 스레드가 존재하는 경우의 통신으로, 전역 변수나 파일을 이용하여 통신
2. 프로세스 간 데이터 통신: 한 컴퓨터에 있는 여러 프로세스끼리의 통신으로, 공용 파일 또는 운영체제가 제공하는 파이프를 사용하여 통신
   - 파이프의 종류
     - 이름 없는 파이프: 일반적인 경우로 부모 자식처럼 관련 있는 프로세스 간 통신에서 사용
     - 이름 있는 파이프: FIFO라 불리는 특수 파일을 이용하여 관련 없는 프로세스 간 통신에 사용
3. 네트워크를 이용한 데이터 통신: 여러 컴퓨터가 네트워크로 연결되어 통신하는 것으로, 프로세스는 소켓을 이용하여 통신(소켓을 이용한 통신을 네트워킹이라고 함)



#### 프로세스 간 통신 방향

1. 양방향 통신: 데이터를 동시에 양쪽 방향으로 전송할 수 있는 구조(ex - 소켓 통신, 일반적인 통신)

2. 반양방향 통신: 양쪽 방향으로 전송할 수 있으나 특정 시점에는 한 쪽 방향만 가능한 구조(ex - 무전기)
3. 단방향 통신: 한쪽 방향으로만 데이터를 전송할 수 있는 구조(ex - 전역 변수와 파이프)



#### 프로세스 간 통신의 구현 방식

- 대기가 있는 통신: 동기화를 지원하는 통신 방식으로, 데이터를 받는 쪽은 데이터가 도착할 때까지 자동으로 대기 상태에 머물러 있음
  - 데이터가 도착했는지는 운영체제가 알려줌

- 대이가 없는 통신: 동기화를 지원하지 않는 통신 방식으로, 데이터를 받는 쪽은 바쁜 대기를 사용하여 데이터가 도착했는지 여부를 직접 확인함
  - 바쁜 대기: 아무것도 하지 않는 빈 반복문을 계속 돌다가 임계 구역에 진입할 수 있을 때 진입하는 방식입니다. 전역 변수를 사용하는 통신 방식에서 두드러지는 문제로 시스템 차원에서 큰 자원낭비입니다.



#### 공유 자원(Share Resource)과 임계 구역(Critical Section)

- 공유 자원은 여러 프로세스가 공동으로 이용하는 변수, 메모리, 파일 등을 의미합니다. 공동으로 이용도므로 누가 언제 어떻게 읽거나 쓰느냐에 따라 결과가 달라질 수 있습니다.
- 임계구역은 공유 자원 접근 순서에 따라 실행 결과가 달라지는 프로그램의 영역을 의미합니다. 따라서 임계구역에서는 동시에 작업을 하면 안됩니다.



#### 임계구역 문제의 해결 조건

1. 상호 배제(Mutual Exclusive): 한 프로세스가 임계구역에 들어가면 다른 프로세스는 임계구역에 들어갈 수 없음
2. 한정 대기(Bounded Waiting): 어떤 프로세스도 무한 대기를 하면 안됨
   - 즉 특정 프로세스가 임계구역에 진입하지 못하면 안됨
3. 진행의 융통성(Progress Flexibility): 한 프로세스가 다른 프로세스의 진행을 방해해서는 안됨



#### 임계구역 문제의 해결 기법

- 세마포어(Semaphore): 사용 전에 초기 설정 `Semaphore(n)`으로 공유 가능한 자원의 수를 정합니다. 이후 임계구역에 들어가기 전에 `P()`로 사용중을 표시합니다. 이때 공유 가능 자원의 수가 0보다 작으면 0보다 커질 때까지 대기합니다. 이후 임계구역을 나올 때  `V()`로 나왔음을 표시합니다.
  - 사용자의 고의나 부주의로 문제가 생길 수 있으므로, 불필요 정보를 숨기고 공유 자원에 대한 인터페이스만 제공하는 모니터를 사용함
    - `wait()`: 모니터 큐에서 자신의 차례가 올 때까지 대기 => `P()`
    - `signal()`: 모니터 큐에서 기다리는 다음 프로세스에 순서를 넘김 => `V()`

- 뮤텍스(Mutex): 한 스레드가 임계구역을 사용할 때, 다른 스레드가 사용하지 못하게 `lock`을 통해 잠궈두고 그 작업이 끝나면 `Unlock`합니다. 이후 대기중인 스레드가 임계구역을 사용하는 방식입니다.

- 세마포어와 뮤텍스의 차이
  - 세마포어는 동기화 대상이 1개 이상인 경우, 뮤텍스는 1개인 경우 사용
  - 세마포어는 뮤텍스가 될 수 있지만, 반대는 불가능
  - 뮤텍스는 소유하고 있는 스레드만이 뮤텍스를 해제할 수 있음, 세마포어는 세마포어를 소유하지 않은 스레드가 세마포어를 해제할 수 있음

<hr>

### 프로세스[교착 상태]

#### 교착 상태

- 2개 이상의 프로세스가 다른 프로세스의 작업이 끝나기만을 기다리며 더 이상 진행하지 못하는 상태입니다. 시스템 자원, 공유 변수, 응용 프로그램 등 다양한 곳에서 발생할 수 있습니다.



#### 교착 상태 필요조건

- 상호 배제: 한 프로세스가 사용하는 자원은 다른 프로세스와 공유할 수 없는 배타적 자원이어야 함
- 비선점: 한 프로세스가 사용 중인 자원은 중간에 다른 프로세스가 빼앗을 수 없어야 함
- 점유와 대기: 프로세스가 어떤 자원을 할당 받고 다른 자원을 기다리는 상태여야 함
- 원형 대기: 점유와 대기를 하는 프로세스 간의 관계가 원을 이루어야 함



#### 교착 상태 해결 방법

- 교착 상태 예방: 네 가지 필요조건이 발생하지 않도록 막는 방법 
  - 실효성이 적어 잘 사용하지 않음
- 교착 상태 회피: 자원 할당량을 조절하여 교착 상태를 해결하는 방법
  - 얼마만큼 할당해야 교착 상태가 발생하지 않는지 알기 어려워 실효성이 적음
- 교착 상태 검출과 회복: 자원 할당 그래프(or 타임아웃 기법)를 모니터링하면서 교착 상태가 발생하는지 확인하는 검출 단계를 진행하다가 발생하면 회복 단계가 진행됨
  - 회복 방법 
    - 교착 상태를 일으킨 모든 프로세스를 동시에 종료하고, 순차적으로 다시 실행
    - 교착 상태를 일으킨 프로세스 중 우선순위, 짧은 프로세스 등의 기준으로 하나를 골라 순서대로 종료



#### 자원 할당 그래프

- 프로세스가 어떤 자원을 사용 중이고 어떤 자원을 기다리고 있는지 방향성이 있는 그래프로 표현한 것입니다. 프로세스는 원으로, 자원은 사각형으로 표현합니다. 또한 자원이 할당된 경우에는 자원에서 프로세스쪽으로 화살표를 표시합니다. 만약  자원이 2개 이상의 프로세스를 동시에 허용하는 경우(다중 지원), 사각형 안에 작은 동그라미로 표현합니다. 



#### 대기 그래프

- 자원 할당 그래프에서 프로세스와 프로세스 간에 기다리는 관계만 나타낸 그래프이다.
  - 감소 그래프: 대기 그래프에서 작업이 끝날 가능성이 있는 프로세스의 화살표와 관련 프로세스의 화살표를 연속적으로 지워나가는 작업을 말한다. 다중 지원이 있는 경우 이렇게 그래프 감소를 완료한 이후에도 사이클이 남아 있다면 교착 상태가 발생한 것으로 간주한다.

<hr>



### 스레드

#### 스레드

- 스레드: 프로세스 내에서 할당받은 자원을 이용해 동작하는 실행 단위
  - 스레드는 프로세스 내에서 Stack만 따로 할당 받고, Code, Data, Heap 영역은 공유한다.
    - (Stack에는 함수의 호출 정보가 저장되는데, Stack을 공유하면 LIFO 구조에 의해 실행 순서가 복잡해지기 때문에 실행 흐름을 원활하게 만들기 위함이다.)
  - 스레드는 프로세스의 자원을 공유하기 때문에 다른 쓰레드에 의한 결과를 즉시 확인가능
    - 변수나 파일 등을 공유하고 전역 변수나 함수 호출의 방법으로 통신함(멀티스레드)
  - 프로세스 내에 존재하며 프로세스가 할당받은 자원을 이용하여 실행



#### 스레드 관련 용어

- 멀티스레드: 프로세스 내 작업을 여러 개의 스레드로 분할함으로써 작업의 부담을 줄이는 프로세스 운영 기법

- 멀티태스킹: 운영체제가 CPU에 작업을 줄 때 시간을 잘게 나누어 배분하는 기법
  - 잘게 나누어주는 시스템을 시분할 시스템이라함

- 멀티프로세싱: CPU를 여러 개 사용하여 여러 개의 스레드를 동시에 처리하는 작업 환경
- CPU 멀티스레드: 스레드를 파이프라인 기법을 이용하여 동시에 여러 스레드를 처리하도록 만든 병렬처리 기법
  - 멀티스레드는 운영체제가 소프트웨어적인 방법으로 운영하는 기법
  - CPU 멀티스레드는 하드웨어적인 방법으로 CPU에서 여러 스레드를 동시에 처리하는 병렬 기법



#### 멀티스레드의 장단점

- 장점
  - 응답성 향상: 한 스레드가 동작하지 않아도 다른 스레드가 동작
  - 자원 공유: 프로세스가 가진 모든 자원을 스레드가 공유하여 작업이 원활
  - 효율성 향상: 불필요한 자원의 중복을 맞아 시스템 효율이 향상
  - 다중 CPU 지원
- 단점
  - 한 스레드에 문제가 생기면 전체 프로세스에 영향을 미침



#### 멀티스레드 모델

- 사용자 스레드: 운영체제가 멀티스레드를 지원하지 않을 때, 라이브러리와 같은 방법으로 구현한 멀티스레드입니다. 하나의 커널 스레드에 여러 사용자 스레드가 연결되어 1:N 모델입니다.
  - 라이브러리가 직접 스케줄링하고 작업에 필요한 정보를 처리하므로 문맥 교환과 같은 부가적인 작업이 없어 속도가 빠릅니다. 하지만 커널 스레드가 입출력을 위해 대기 상태로 들어가면 모든 사용자 스레드가 같이 대기합니다. 또한 한 타임 슬라이스를 모든 스레드가 공유하므로 여러 개의 CPU를 동시에 사용할 수 없습니다.
- 커널 스레드: 커널이 멀티스레드를 지원하는 방식으로, 하나의 커널 스레드와 하나의 사용자 스레드가 연결되어 1:1 모델입니다.
  - 멀티 CPU를 활용할 수 있고, 하나의 스레드가 대기 상태에 있어도 다른 스레드는 작업할 수 있습니다. 또한 커널의 기능을 사용하므로 보안에 강하고 안정적입니다. 하지만 문맥 교환을 할 때 오버헤드로 인해 느리게 동작합니다.
- 멀티레벨 스레드: 사용자 스레드와 커널 스레드를 혼합한 방식으로 M:N 모델입니다. 사용자 스레드와 커널 스레드의 장점을 모두 가지고 있습니다. 따라서 빠르게 움직여야 하는 스레드는 사용자 스레드로 작동하고, 안정적으로 움직여야 하는 스레드는 커널 스레드로 작동합니다.
  - 하나의 커널 스레드가 대기 상태에 들어가면 다른 커널 스레드가 대신 작업을 하여 사용자 스레드보다 유연합니다. 하지만 여러 커널 스레드를 사용하여 여전히 문맥 교환이 있어 사용자 스레드만큼 빠르지 않습니다.

<hr>



### CPU 스케줄링

#### 고수준 스케줄링, 중간수준 스케줄링, 저수준 스케줄링

- 고수준 스케줄링: 전체 시스템의 부하를 고려하여 작업을 시작할지 말지를 결정합니다.

- 중간수준 스케줄링: 전체 시스템에 활성화된 프로세스 수를 조절하여 과부하를 방지합니다.
- 저수준 스케줄링: 어떤 프로세스를 선택할지, 어떤 기준에 따라 타임 슬라이스를 정할지 등 시스템 성능에 큰 영향을 미치는 스케줄링입니다.



#### 스케줄링의 목적

- 모든 프로세스가 공평하게 작업하도록 하는 것
  - 공평성: 모든 프로세스가 자원을 공평하게 배정받아야 함(특정 프로세스가 배제되면 X)
  - 효율성: 시스템 자원이 유휴 시간 없이 사용되도록 스케줄링 하고, 유휴 자원을 사용하려는 프로세스에는 우선권을 주어야 함
  - 안정성: 우선순위를 사용하여 중요 프로세스가 먼저 작동하도록 배정함으로써 시스템 자원을 점유하거나 파괴하려는 프로세스로부터 자원을 보호
  - 확장성: 프로세스가 증가해도 시스템이 안정적으로 작동하도록 조치
    - 시스템 자원이 늘어나는 경우 이 혜택이 시스템에 반영되게 해야한다.
  - 반응 시간 보장: 시스템은 적절한 시간 안에 프로세스의 요구에 반응해야 한다.
  - 무한 연기 방지: 특정 프로세스의 작업이 무한히 연기되어서는 안된다.



#### CPU 스케줄링의 성능평가 기준

- CPU 사용률: 전체 시스템의 동작 시간 중 CPU가 사용된 시간을 측정하는 방법
- 처리량: 단위 시간당 작업을 마친 프로세스의 수
- 대기 시간: 작업을 요청한 프로세스가 작업을 시작하기 전까지 대기하는 시간
- 응답 시간: 프로세스 시작 후 첫 번째 출력 또는 반응이 나올 때까지 걸리는 시간
- 반환 시간: 프로세스가 생성된 후 종료되어 자원을 모두 반환하는 데까지 걸리는 시간



#### 고정 우선순위와 변동 우선순위

- 고정 우선순위 방식은 운영체제가 프로세스의 우선순위를 부여하면 프로세스가 끝날 때까지 바뀌지 않는 방식입니다. 구현은 쉬우나 시스템 변화에 대응하기 어려워 작업 효율이 떨어집니다.
- 변동 우선순위 방식은 프로세스 생성 시 부여받은 우선순위가 프로세스 작업 중간에 변하는 방식입니다. 구현은 어려우나 시스템 효율성을 높일 수 있습니다.



#### 선점형 스케줄링과 비선점형 스케줄링

- 선점형 스케줄링은 어떤 프로세스가 실행중이라도 운영체제가 강제로 CPU를 빼앗을 수 있는 스케줄링 방식입니다. 대표적으로 인터럽트가 있고, 문맥 교환으로 낭비가 발생합니다. 
- 비선점형 스케줄링은 어떤 프로세스가 CPU를 점유하면 다른 프로세스가 이를 빼앗을 수 없는 스케줄링 방식입니다. 문맥 교환이 없어 오버헤드가 없으나 기다리는 프로세스가 많아 처리율이 떨어집니다.



#### 선점형 스케줄링

- 라운드 로빈 스케줄링(순환 순서 방식): 한 프로세스가 할당받은 시간(타임 슬라이스) 동안 작업을 하다가 완료하지 못하면 준비 큐의 맨 뒤로 가서 다시 차례를 기다리는 방식
  - 타임 슬라이스가 너무 크면 FCFS의 스케줄링이 되고, 너무 짧다면 문맥 교환이 많아짐
- SRT 스케줄링(최소 잔류 시간 우선 스케줄링): 라운드 로빈을 기본으로, CPU를 할당받을 프로세스를 선택할 때 작업 시간이 가장 적은 프로세스를 선택하는 방식
- 다단계 큐 스케줄링: 라운드 로빈을 기본으로, 우선순위에 따라 준비 큐를 여러 개 사용하고 고정 우선순위를 사용하는 방식

- 다단계 피드백 큐 스케줄링: 우선순위가 낮은 프로세스에게 불리한 다단계 큐 스케줄링의 문제점을 보완한 방식이다. CPU를 사용하고 나면 원래 프로세스의 우선순위에서 하나 낮은 큐에 끝으로 들어가고, 우선순위가 낮을수록 타임 슬라이스가 증가한다.



#### 비선점형 스케줄링

- FCFS 스케줄링(선입선출 스케줄링): 준비 큐에 도착한 순서대로 CPU에 할당하는 방식으로 큐가 하나라 모든 우선순위가 동일
- SJF 스케줄링(최단 작업 우선순위 스케줄링): 준비 큐에 있는 프로세스 중 실행 시간이 가장 짧은 작업부터 CPU를 할당하는 방식
- HRN 스케줄링(최고 응답률 스케줄링): 우선순위(에이징)를 구현하여 SJF에서 발생하는 아사 현상을 해결하기 위한 방식
  - 우선순위 = (대기시간 + CPU 사용 시간) / (CPU 사용 시간)



- 우선순위 스케줄링: 선점형과 비선점형이 모두 가능한 스케줄링으로 구현 방식에 따라 달라짐

<hr>



### 버스

#### 버스의 종류

- 제어 버스(Control Bus): 데이터 버스와 주소 버스를 제어하기 위해 제어 신호들을 전송하는 버스를 말한다. 제어장치(CU)와 연결되어 있으며 양방향이다.
- 주소 버스(Address Bus): CPU가 메모리나 주변 장치로 기억장치 주소로 전달하는 버스를 말한다. 메모리 주소 레지스터(MAR)와 연결되어 있으며 주소만 전달하므로 단방향이다.
- 데이터 버스(Data Bus): CPU와 기타 장치 사이에서 데이터를 전달하는 버스로, 제어가 다음에 어떤 작업을 할지 신호를 보내주고 주소 버스가 위치 정보를 전달하면 데이터가 데이터 버스에 실려 목적지까지 이동한다. 메모리 버퍼 레지스터(MBR)와 연결되어 있으며 양방향이다.



#### 버스 대역폭

- 데이터가 버스를 통해 단위 시간당 전송하는 데이터의 크기를 말합니다.

<hr>



### 캐시

#### 캐시

- 메모리와 CPU 간의 속도 차이를 완화하기 위해 메모리의 데이터를 미리 가져와 저장해두는 임시 저장소입니다. 버퍼의 일종으로 CPU 내부에 있어 CPU 내부 버스의 속도로 작동합니다.



#### 캐시 히트와 캐시 미스

- 캐시 히트는 캐시에서 원하는 데이터를 찾았을 때를 의미하고, 원하는 데이터가 없다면 캐시 미스라고 합니다. 여기서 캐시 히트가 되는 비율을 캐시 적중률이라 합니다.



#### 즉시 쓰기와 지연 쓰기

- 즉시 쓰기(Write Through): 캐시에 있는 데이터가 변경되면 이를 즉시 메모리에 반영하는 방식
  - 메모리의 값이 항상 최신으로 유지되어 돌발 상황에도 데이터를 잃어버리지 않음
  - 메모리와 빈번한 데이터 전송으로 성능이 느려짐
- 지연 쓰기(Write Back): 캐시에 있는 데이터가 변경되면 변경된 내용을 모아 주기적으로 반영하는 방식으로 카피백이라고도 함
  - 메모리와의 데이터 전송이 줄어들어 시스템 성능 향상
  - 메모리와 캐시 사이의 데이터 불일치가 발생할 수 있음



#### 3단계 캐시(L1, L2, L3)

- CPU는 L1, L2 L3 순으로 CPU와 가깝고 속도도 빠르지만, 용량은 반대입니다. 또한 가까운 순서대로 데이터를 찾습니다.
- L1 캐시는 명령어를 저장하는 명령어 레지스터와 연결된 명령어 캐시와 데이터를 저장하는 데이터 레지스터와 연결된 데이터 캐시로 나뉩니다. L2 캐시는 CPU가 곧 사용할 명령과 데이터를 저장하며 L1처럼 둘로 나누지 않습니다. L3캐시도 L2와 동일한 원리로 작동하나 일반적으로 성능에 큰 영향을 미치지 않으며 메인보드에 내장되는 경우가 더 많습니다.



#### 캐시 매핑 방식(직접 매핑 | 연관 매핑 | 집합-연관 매핑)

- 직접 매핑: 블록(캐시의 크기)을 지정하고 메모리를 블록들로 구성합니다. 캐시의 인덱스(`bd`)에는 해당 인덱스와 같은 `bd`를 가진 메모리의 값들만 올라올 수 있습니다. 그리고 이때 메모리의 `tag`를 캐시의 `tag` 부분에 저장합니다. 이런 방식은 만약 물리 주소의 `1101`이 필요하다면 캐시의 `01`위치의 `tag`가 `11`인지만 검사하면 됩니다.
  - `<P,D>`를 `<tag,bd,D>`로 바꿀 수 있음
    - `P`=페이지 번호, `D`=페이지 내에서 거리, `tag`=블록의 번호, `bd`=블록에서의 거리
  - 캐시 히트나 캐시 미스를 빠르게 확인할 수 있음
  - 캐시의 특정 인덱스(`bd`)에서 메모리에 있는 값들이 연속적으로 필요한 경우 캐시 적중률이 떨어짐
- 연관 매핑: 캐시가 메모리의 주소를 전부 가지고 있으면서 매핑하는 방식입니다. 이는 직접 매핑의 경우 `bd`를 인덱스 번호로 가지고 있었지만, 연관 매핑은 `bd`와 `tag`를 모두 열로 가지고 있다는 것을 의미합니다.
  - 캐시 메모리를 자유롭게 사용할 수 있음
  - 캐시 히트인지 캐시 미스인지 확인하기 위해 모든 주소를 검색해야 함
- 캐시 집합-연관 매핑: 캐시를 K개의 집합으로 나누고 각 집합에 직접 매핑을 사용하는 방식입니다. 같은 끝자리를 가진 캐시 메모리가 K개가 되기 때문에 직접 매핑의 자리다툼 문제가 완화되면서도, 캐시 히트와 캐시 미스 여부를 모든 캐시를 뒤지지 않고 알 수 있습니다.

<hr>



### CPU와 입출력 장치의 속도 차이를 개선하기 위한 기법

#### 버퍼(Buffer)

- 데이터를 한 곳에서 다른 곳으로 전송하는 동안 그 데이터를 저장하는 메모리의 영역입니다. 일정량의 데이터를 모아 옮김으로써 속도의 차이를 완화하는 기법입니다. 여기서 버퍼링은 버퍼를 활용하는 방식 또는 버퍼를 채우는 동작을 의미합니다.
  - 이중 버퍼: 한 버퍼는 데이터를 담는 용도로 사용하고 다른 버퍼는 데이터를 가져오는 용도로 사용하여 두 작업을 동시에 수행할 수 있게 만들 수 있음
  - 플러시: 버퍼가 다 차지 않아도 강제로 버퍼의 내용을 저장장치로 옮기는 것(주로 하드웨어 안전 제거를 사용했을 때 발생함)



#### 스풀(Spool)

- CPU와 입출력 장치가 독립적으로 동작하게 만들어 CPU에 비해 주변 장치가 느려 발생하는 대기시간을 줄이기 위해 고안된 기법입니다. 여기서 스풀링은 스풀을 적용하는 것 또는 스풀을 위해 마련된 공간에 채우는 동작을 의미합니다.



#### 버퍼링과 스풀링의 공통점과 차이점

- 공통점은 두 기법 모두 CPU의 처리 속도와 입출력 장치의 속도 차이를 보완하기 위한 방법이라는 것입니다. 차이점은 버퍼는 주기억장치의 일부를 스풀은 보조기억장치의 일부를 사용한다는 것입니다. 또한 버퍼링 단일 작업을 수행하지만, 스풀링은 다중 작업이 가능합니다.

<hr>



### 병렬처리

#### 병렬처리

- 동시에 여러 개의 명령을 사용하여 작업의 능률을 올리는 방식을 의미합니다.



#### 병렬처리 시 고려사항

1. 상호 의존성이 없어야 병렬 처리가 가능
2. 각 단계의 시간을 거의 일정하게 맞춰야 병렬 처리가 원만
3. 전체 작업 시간을 몇 단계로 나눌지 고려



#### 병렬처리의 기법

1. 파이프라인 기법: CPU 사용을 극대화하기 위해 명령을 겹쳐서 실행하는 방법으로, 하나의 코어에 여러 스레드를 사용하는 것을 의미합니다.
   - 파이프라인의 위험(파이프라인 기법의 문제)
     - 데이터 위험: 데이터 의존성 때문에 발생하는 문제
     - 제어 위험: 프로그램 카운터 값을 갑자기 변화시켜 발생하는 문제(ex - `goto`문)
     - 구조 위험: 서로 다른 명령어가 같은 자원에 접근하려 할 때 발생하는 문제

2. 슈퍼스칼라 기법: 파이프라인이 처리할 수 있는 코어를 여러 개 구성하여 복수 명령어가 동시에 수행되도록 하는 방식입니다. 즉 파이프라인 기법을 여러 개의 코어에서 동시에 수행하는 방식을 말합니다.

3. 슈퍼파이프라인 기법: 한 클록마다 하나의 명령어를 실행하는 것이 아닌 파이프라인의 각 단계를 세분화하여 한 클록 내에 여러 명령어를 처리하는 기법입니다.

4. 슈퍼파이프라인 슈퍼스칼라 기법: 슈퍼파이프라인 기법을 여러 개의 코어에서 동시에 수행하는 방식입니다.
5. VLIW 기법: CPU가 병렬처리를 지원하지 않을 경우 소프트웨어적으로 처리하는 방법입니다.

<hr>

### 기타

#### 32bit CPU와 64bit CPU의 차이

- bit의 크기는 한 번에 다룰 수 있는 데이터의 최대 크기, 버스 대역폭의 크기, 메모리의 주소 공간의 크기를 결정한다.





## 3. 메모리

### 메모리[개요]

#### 메모리

- 메모리는 컴퓨터에서 작업을 수행하기 위해 처리 대상이나 결과 등을 저장하기 위한 공간입니다. 프로그램을 실행하기 위한 정보들은 메모리에 저장되어 처리됩니다.



#### 메모리의 종류

- 휘발성 메모리(Volatility Memory): 전원이 공급되는 동안에만 데이터를 보관할 수 있는 메모리입니다. 주기억장치로 많이 활용되며 DRAM, SRAM 등이 있습니다.
- 비휘발성 메모리(Non-volatility Memory): 전원이 공급되지 않아도 저장된 정보를 계속 유지하는 메모리입니다. 보조기억 장치로 많이 사용되며 플래시 메모리, FRAM, PRAM 등이 있습니다.



#### 메모리 접근 권한

- 메모리의 특정 주소에 저장된 데이터를 사용할 수 있는 권한으로 `읽기`, `쓰기`, `실행`, `추가` 권한이 있습니다. 네 가지의 권한은 복합적으로 사용되는데, 이때 `추가`의 경우 항상 `쓰기`의 권한이 동반되어야 합니다. 따라서 3가지의 권한의 조합인 8가지의 접근 방식이 만들어집니다. 이런 접근 권한 검사는 가상 주소에서 물리 주소로 변환이 일어날 때마다 시행됩니다.

<hr>



### 메모리[관리]

#### 메모리 관리자(or 메모리 관리 유닛(MMU; Memory Manage Unit))

- 메모리 관리를 담당하며 주 역할은 다음과 같다.
  - 가져오기 작업: 프로세스와 데이터를 메모리로 가져오는 작업
    - 가져오기 정책: 언제 가져올지 결정하는 정책(미리 가져오기도 함)
  - 배치 작업: 가져온 프로세스와 데이터를 메모리의 어떤 부분에 올려놓을지 결정하는 작업
    - 배치 정책: 어떤 위치에 올려놓을지 결정하는 정책(페이지, 세그먼테이션)
  - 재배치 작업: 꽉 차 있는 메모리에서 새로운 프로세스를 가져오기 위해 오래된 프로세스를 내보는 작업
    - 재배치 정책: 어떤 프로세스를 내보낼지 결정하는 정책(교체 알고리즘)



#### 메모리 배치 정책

- 메모리 분할 방식
  - 가변 분할 방식: 프로세스의 크기에 따라 메모리는 나누는 것 
    - 메모리 단위는 세그먼테이션
    - 하나의 프로세스가 연속된 공간에 배치
    - 메모리 통합 등 부가적 작업이 필요하여 메모리 관리 방식이 복잡
    - 외부 단편화가 발생
      - 메모리 배치 방식
        - 최초 배치: 적재 가능한 공간을 순서대로 찾다가 처음 발견한 공간에 배치
        - 최적 배치: 빈 공간을 모두 확인 후 적재 가능한 가장 작은 공간에 배치
        - 최악 배치: 빈 공간을 모두 확인 후 적재 가능한 가장 큰 공간에 배치
  - 고정 분할 방식: 프로세스의 크기와 상관없이 메모리를 같은 크기로 나누는 것
    - 메모리 단위는 페이징
    - 메모리 관리가 수월
    - 하나의 프로세스가 비연속적 공간에 배치될 수 있음
    - 내부 단편화가 발생하여 메모리 낭비가 발생



#### 버디 시스템

- 외부 단편화를 완화하는 방법으로 가변 분할과 고정 분할의 중간 구조입니다. 프로세스를 배치할 때 메모리를 프로세스 크기에 맞게 1/2 크기로 잘라나가며 배치합니다. 이러한 방식은 비슷한 크기에 조각이 서로 모여 있어 작은 조각을 통합하기 쉽습니다. 공간 관리 측면에서는 고정 분할 방식과 비슷하나 메모리 관리 측면에서 고정 분할보다 복잡하여 잘 사용되지 않습니다.



#### 메모리 영역의 구분

- 메모리 관리자는 사용자가 운영체제의 영역을 침범하지 못하도록 메모리를 운영체제 영역과 사용자 영역으로 나누어 관리합니다. CPU 내에 있는 경계 레지스터를 통해 메모리 관리자는 사용자가 작업을 요청할 때마다 경계 레지스터의 값을 벗어나는지 검사하고, 벗어나면 종료하는 방식으로 침범을 막습니다.



#### 절대 주소와 상대 주소

- 절대 주소는 메모리 관리자 입장에서 바라본 주소로, 물리 주소 0번지를 주소 시작점으로 삼아 절대 주소가 물리 주소의 실제 공간입니다.
- 상대 주소는 사용자 프로세스 입장에서 바라본 주소로, 사용자 영역이 시작되는 주소를 주소 시작점으로 삼는 논리 주소입니다. 따라서 상대 주소를 사용하기 위해서는 물리 주소로 변환해야 하는데, 메모리 관리자는 메모리에 접근할 때 상대 주소값에 재배치 레지스터 값을 더하여 절대 주소를 구합니다.



#### 메모리 오버레이

- 프로그램이 실제 메모리보다 클 때 전체 프로그램을 가져오는 대신 적당한 크기로 잘라 가져오는 기법입니다. 프로그램을 몇 개의 모듈로 나누고 필요할 때마다 모듈을 메모리로 가져와 사용합니다. 어떤 모듈을 가져올지 내보낼지는 프로그램 카운터(PC)가 결정합니다.
  - 스왑 영역: 메모리가 모자라 쫓겨난 프로세스가 모이는 영역으로 제2저장장치에 존재하며 메모리 관리자가 관리합니다. 메모리 오버레이에서는 실제 메모리 크기와 스왑 영역의 크기를 합쳐 전체 메모리로 인식하고 사용할 수 있습니다.
    - 스왑인: 스왑 영역에서 메모리로 데이터를 가져오는 작업
    - 스왑아웃: 메모리에서 스왑 영역으로 데이터를 내보내는 작업



#### 컴파일러와 인터프리터

- 컴파일러: 소스코드를 컴퓨터가 실행할 수 있는 기계어로 번역한 후 한꺼번에 실행하는 방법으로 C언어, 자바 등이 있다.

- 인터프리터: 소스코드를 한 행씩 번역하여 실행하는 것으로 자바스크립트, 파이썬 등이 있다.

- 컴파일러와 인터프리터의 차이

  | 구분 | 컴파일러                                              | 인터프리터                |
  | ---- | ----------------------------------------------------- | ------------------------- |
  | 변수 | 변수를 미리 선언                                      | 변수를 선언할 필요가 없음 |
  | 실행 | 컴파일 후 실행                                        | 한 줄씩 실행              |
  | 장점 | 오류 찾기, 코드 최적화, 공동 작업이 가능(분할 컴파일) | 실행이 편리               |
  | 사용 | 대형 프로그램                                         | 간단한 프로그램           |



#### 컴파일러의 목적

- 심벌 테이블을 활용하여 오류를 찾고, 중복된 코드는 제거하고 불필요 코드는 삭제하여 코드 최적화를 진행





## 4. 가상 메모리

### 가상 메모리[개요]

#### 가상 메모리

- 가상 메모리는 메모리를 관리하는 방법의 하나로, 각 프로그램에 실제 메모리 주소가 아닌 가상의 메모리 주소를 주는 방식입니다. 이러한 방식은 멀티태스킹 운영 체제에서 흔히 사용되며, 실제 주기억장치보다 큰 메모리 영역을 제공하는 방법으로 사용됩니다.



#### 동적 주소 변환(DAT; Dynamic Address Translation)

- 가상 메모리 시스템에서 메모리 관리자가 물리 메모리와 스왑 영역을 합쳐서 프로세스가 사용하는 가상 주소를 실제 메모리의 물리 주소로 변환하는 작업



#### 매핑 테이블(Mapping Table)

- 메모리 관리자가 가상 주소를 물리 주소로 변환하기 위해 가상 주소와 물리 주소를 일대일로 관리하는 테이블

<hr>



### 가상 페이지[관리]

#### 요구 페이징(Demand Paging)

- 실행 중인 프로세스가 요구하는 해당 페이지를 메모리로 가져오는 것을 의미합니다. 메모리의 낭비를 줄일 수 있지만, 페이지 부재를 많이 발생시킵니다.
  - 스와핑(Swapping): 프로세스 자체를 스왑인 및 스왑아웃하는 동작
  - 순수한 스와핑(Pure Swapping): 프로세스 단위로 스와핑하는 동작
  - 게으른 스와퍼(Lazy Swapper): 요구 페이징



#### 페이징 부재(Paging Fault)

- 프로세스가 페이지를 요청했을 때 그 페이지가 메모리에 없는 상황을 의미합니다. 즉 페이지 테이블 엔트리(PTE)의 유효 비트가 1인 상황을 말합니다. 페이지 부재가 발생하면 메모리 관리자는 PTE의 주소 필드를 읽고 스왑 영역의 주소에 접근하고 해당 페이지를 빈 메모리로 가져옵니다. 이후 해당 PTE의 유효 비트를 0으로 바꾸고 해당 메모리의 페이지를 주소 필드에 적습니다. 
  - 페이지를 가져와야 하는데 메모리가 꽉 차 있었다면 교체 알고리즘을 통해 페이지를 스왑 영역에 보내는데 이때 보내지는 페이지를 대상 페이지라고 함



#### 지역성(Locality)

- 기억 장치에 접근하는 패턴이 메모리 전체에 고루 분포되는 것이 아닌 특정 영역에 집중되는 성질을 말합니다.
  - 공간의 지역성: 현재 위치에서 가까운 데이터에 접근할 확률이  먼 거리보다 더 높음
  - 시간의 지역성: 현재를 기준으로 가장 가까운 시간에 접근한 데이터에 접근할 확률이 먼 시간에 접근하 데이터보다 높음
  - 순차적 지역성: 여러 자업이 순서대로 진행되는 경향이 있음
    - 경우에 따라 순차적 지역성을 공간의 지역성의 특수 경우로 보기도 함



#### 스레싱(Threshing)

- 메모리가 꽉 차서 CPU가 작업하는 시간보다 스왑 영역으로 페이지를 보내고 메모리에서 페이지를 가져오는 작업이 빈번해져 CPU 사용률이 떨어지는 현상을 말합니다. 이때 이러한 스레싱이 발생하는 시점을 스레싱 발생 지점이라고 합니다. 스레싱은 프레인 할당 문제와도 연관됩니다. 또한 스레싱 발생 지점은 물리 메모리의 크기를 늘리면 일정 수준까지는 지연시킬 수 있습니다.



#### 프레임 할당

- 정적 할당: 실행 초기에 프레임을 나눠준 후 그 크기를 고정하는 것
  - 균등 할당: 프로세스 크기와 상관 없이 사용 가능한 프레임을 모든 프로세스에 동일하게 할당
    - 큰 프로세스는 페이지 부재가 작은 프로세스는 메모리가 낭비됨
  - 비례 할당: 프레세스의 크기에 따라 프레임을 할당하는 방식
    - 프로세스가 실행 중 필요로 하는 프레임을 유동적으로 반영하지 못함
    - 사용하지 않을 메모리를 미리 확보하여 공간이 낭비
- 동적 할당: 프로세스가 실행하면서 프레임의 크기가 변하는 것
  - 작업집합 모델: 물리 메모리에 유지할 페이지의 크기인 작업집합 크기를 설정하고, 작업집합에 포함되는 페이지 범위인 작업집합 윈도우를 설정한다. 작업집합 크기만큼 페이지에 접근할 때마다 작업집합을 갱신하는데 이때 작업집합 윈도우에 있는 숫자들로 갱신한다. 만약 작업집합 크기보다 더 많은 페이지가 있다면 현재 다음에 접근할 페이지 + 작업집합 윈도우의 시점에 가까운 것들을 넣는다.
  - 페이지 부재 빈도: 페이지 부재 횟수를 기록하여 페이지 부재 비율을 계산하는 방식으로 페이지 부재 비율의 상한선과 하한선을 설정한다. 페이지 부재 비율이 상한선을 넘어가면 프레임을 늘리고, 반대라면 페이지를 줄인다.

<hr>



### 페이지 교체 알고리즘

#### 페이지 교체 알고리즘

- 페이지 부재가 발생하여 메모리 관리자가 새로운 페이지를 메모리로 가져올 때, 메모리가 꽉 차 있다면 기존에 있던 메모리를 내보내야 합니다. 이때 페이지 교체 알고리즘이 사용됩니다.
  - 성능 평가는 주로 페이지 부재 횟수와 페이지 성공 횟수



#### 페이지 교체 알고리즘 종류

| 종류               | 알고리즘  | 특징                                                |
| ------------------ | --------- | --------------------------------------------------- |
| 간단한 알고리즘    | 무작위    | 무작위로 대상 페이지를 선정하여 스왑 영역으로 보냄  |
|                    | FIFO      | 처음 메모리에 올라온 페이지를 스왑 영역으로 보냄    |
| 이론적 알고리즘    | 최적      | 미래의 접근 패턴을 보고 대상 페이지를 선정하여 보냄 |
| 최적 근접 알고리즘 | LRU       | 시간적으로 멀리 떨어진 페이지를 스왑 영역으로 보냄  |
|                    | LFU       | 사용 빈도가 적은 페이지를 스왑 영역으로 보냄        |
|                    | NUR       | 최근에 사용한 적 없는 페이지를 스왑 영역으로 보냄   |
|                    | FIFO 변형 | FIFO 알고리즘을 변형하여 성능을 높임                |

- 무작위: 지역성을 전혀 고려하지 않아 성능이 안좋음
- FIFO: 메모리에 올라온 시간만을 고려하여 대상 페이지를 선정하므로 성능이 떨어짐
- 최적: 미래의 페이지 접근을 알 수 없기 때문에 이상적인 알고리즘 => 구현 안됨
- LRU: 구현 방식에 따라 여러가지가 존재(어떤 방법이나 메모리 낭비가 많음)
  - 접근 시간에 기반: 접근 시간을 기록하고 숫자가 가장 작은 페이지를 교체함
  - 카운터에 기반: 시간(초) 대신 카운터를 사용하여 구현
  - 참조 비트 시프트 방식: 일정 크기의 참조 비트를 만들고(초기값 0), 접근할 때마다 1로 바꾸며 주기적으로 오른쪽으로 한 칸씩 이동(이후 가장 최근에 참조하지 않은 페이지를 대상 페이지로)
- LFU: 처음 메모리에 올라온 페이지의 사용 빈도는 1이고, 페이지가 사용될 때마다 1씩 증가함(메모리 낭비)
- NUR: 페이지마다 참조 비트(PTE 접근 비트)와 변경 비트(PTE 변경 비트)를 사용하여 구현함
  - (참조 비트, 변경 비트)로 초기값은 (0,0)으로 지정하고 접근 또는 변경이 발생하면 해당 위치를 1로 바꾼다. 대상 페이지를 선정할 때 (0,0) => (0,1) => (1,0) => (1,1) 순으로 선택하고 같은 경우는 무작위로 선정한다. (만약 모두 (1,1)이면 (0,0)으로 초기화함)
  - NRU, NFU와 성능이 비슷하면서 메모리 낭비를 제거한 방법

- FIFO 변형
  - 2차 기회 FIFO: 페이지 참조에 성공할 경우 큐의 맨 뒤로 이동하여 기회를 줌
    - NRU, NFU보다 성능이 약간 낮음
    - 큐를 유지하는 비용이 높고, 맨 뒤로 이동하는 작업이 있는 것은 단점
  - 시계: 메모리가 꽉 찬 경우 원형 큐를 사용하여 포인터가 맨 위에서 맨 아래를 가리키는 것을 반복한다. 이때 포인터가 가리키는 페이지가 대상 페이지이다. 또한 참조 비트를 사용하여 페이지 참조 시 0 => 1로 변경하는데, 포인터가 가리키는 참조 비트가 1이라면 아래로 넘어가면서 0으로 다시 바꾼다.
    - NUR보다 추가 공간이 적음
    - 알고리즘이 복잡하고 계산량이 많음



#### 전역 교체와 지역 교체

- 전역 교체: 전체 프레임을 대상으로 교체 알고리즘을 적용
- 지역 교체: 현재 실행 중인 프로세스의 프레임을 대상으로 교체 알고리즘을 적용
  - 다른 프로세스의 스레싱을 줄일 수 있지만 반대로 실행 중인 프로세스의 성능을 떨어뜨릴 수 있음

<hr>



### 페이징 기법

#### 페이지 기법

- 고정 분할 방식을 이용한 가상 메모리 관리 기법으로, 물리 주소 공간을 같은 크기로 나누어 사용하는 것입니다.가상 주소의 분할된 각 영역은 페이지로, 물리 메모리의 분할된 각 영역은 프레임이라고 부르며 둘의 크기는 같습니다. 페이지와 프레임은 번호를 매겨 관리합니다. 



#### 페이지 테이블

- 페이지와 프레임의 번호를 매칭해놓은 테이블입니다. 하나의 열로 구성되며 해당 열에는 프레임 번호가 써있고, 인덱스 번호는 페이지 번호입니다. 만약 해당 인덱스와 매칭되는 프레임이 없다면 `invalid`로 표시되어 있습니다. 이때 각각의 한 줄은 페이지 테이블 엔트리(PTE)라고 부르며 페이지 테이블 시작 주소는 페이지 테이블 기준 레지스터(PTBR)이 가지고 있습니다.



#### 페이지 테이블 엔트리(PTE) 구조

- 페이지 번호: 직접 매핑에서는 필요 없으나 연관 매핑에서는 필요함
- 플래그 비트
  - 접근 비트(Access bit): 페이지가 메모리에 올라온 후 사용한 적 있는지(1) 나타내는 비트
  - 변경 비트(Modified bit): 페이지가 메모리에 올라온 후 데이터의 변경이 있었는지(1) 나타내는 비트
  - 유효 비트(Valid bit): 페이지가 실제 메모리에 있는지(0) 나타내는 비트
  - 읽기, 쓰기, 실행 비트: 페이지에 대한 읽기, 쓰기, 실행 권한을 나타내는 비트

- 프레임 번호: 해당 페이지가 어느 프레임에 있는지 알려주는 자료 구조(메모리든 스왑 영역이든)



#### 테이블 매핑 방식

- 직접 매핑: 페이지 테이블 전체가 물리 메모리 영역에 존재하는 방식으로 별다른 부가 작업 없이 주소 변환이 가능합니다.
- 연관 매핑: 페이지 테이블 전체를 스왑 영역에서 관리하는 방식으로 랜덤한 일부만 물리 메모리에 가지고 있습니다. 따라서 페이지 테이블이 페이지 번호와 프레임 번호를 모두 표시하여 연관 매핑은 매핑을 바로 할 수 없고 해당 페이지 번호를 찾아야합니다. 이때 메모리에 해당 페이지가 없으면(있으면 TLB 히트) 스왑 영역에서(TBL 미스) 찾아야합니다.
  - 대부분 물리 메모리의 크기가 작을 때 사용합니다. 
- 집합-연관 매핑: 페이지 테이블을 일정한 크기로 자르고, 자른 덩어리 단위로 물리 메모리로 가져오는 연관 매핑의 문제를 개선한 방식입니다. 집합 테이블을 생성하여 일정한 크기로 자른 페이지 테이블이 스왑영역에 있는지 없는지 표현합니다. `I`로 표시된 것은 스왑 영역에 있다는 것이므로 연관 매핑과 다르게 모든 페이지 테이블을 검사할 필요가 없어 시간이 단축됩니다.
- 역매핑: 물리 메모리의 프레임 번호를 기준으로 테이블을 구성합니다. 즉 인덱스는 페이지 번호이고 열은 PID와 프레임이 있습니다. 이러한 방식은 프로세스 수와 상관없이 테이블이 하나만 존재하므로 테이블 크기가 매우 작습니다. 하지만 가상 메모리에 접근할 때 프로세스 아이디와 페이지 번호를 모두 찾아야하므로 속도가 매우 느립니다.



#### 주소 변환 과정

- 페이징 기법에서는 가상 주소를 `VA=<P,D>`라고 표현합니다. 물리 주소는 `PA=<P,D>`로 표현합니다. 이 `VA`를 `PA`로 변환하는 것을 의미합니다.
  - `VA`=가상주소, `P`=페이지, `D`=페이지의 처음 위치에서 해당 주소까지의 거리
  - `PA`=물리주소, `F`=프레임, `D`=프레임의 처음 위치에서 해당 주소까지의 거리

<hr>



### 세그먼테이션 기법

#### 세그먼테이션 기법

- 가변 분할 방식을 사용한 가상 메모리 관리 기법으로, 물리 주소 공간을 프로세스 크기에 따라 가변적으로 나눈 것입니다. 



#### 세그먼테이션 테이블

- 세그먼트의 크기를 나타내는 `limit`와 물리 메모리상의 시작 주소를 나타내는 `address`가 있습니다. 만약 물리 메모리가 스왑 영역에 있다면 `address`에 `I`로 표시합니다.



#### 주소 변환 과정

1. 사용자가 어떤 주소에 데이터를 요청하면 가상 주소`VA=<S,D>`를 구함
2. `S`의 시작 주소에서 `D`를 더하여 물리 주소를 구하고, 세그먼트의 `limit`보다 큰지 점검
3.  만약 정상이라면 해당 물리 주소에 접근하여 데이터를 읽거나 씀
   - `VA`=가상주소, `S`=세그먼트 번호, `D`=세그먼트 시작 위치에서 해당 주소까지의 거리



### 세그먼테이션-페이징 혼용 기법

- 페이징 기법과 세그먼테이션 기법의 장점만을 취한 기법입니다. 페이징에서 권한 비트로 인해 중복되어 메모리가 메모리를 낭비하는 점을 세그먼테이션 테이블로 해결합니다. 즉 페이지로 분할된 가상 주소 공간에서 서로 관련 있는 영역을 하나의 세그먼트로 묶어 세그먼테이션 테이블로 관리하고, 각 세그먼트를 구성하는 페이지를 해당 테이블 페이지로 관리하는 기법입니다.
  - 권한 비트뿐만 아니라 유닉스의 경우 소유자 및 권한에 대한 부분도 중복을 방지할 수 있음



#### 주소 변환 과정

1. 사용자가 어떤 주소의 데이터를 요청하면 해당 주소가 몇 번째 세그먼트의 몇 번째 페이지로부터 얼마나 떨어져 있는지 계산하여 `VA=<S,P,D>`를 구함
2. 세그먼테이션 테이블의 해당 세그먼트 번호로 가서 자신의 영역이 벗어나는 불법 접근이 아닌지, 권한이 없는 페이지에 접근하는 것인지 확인한다. 정상인 경우 연결된 페이지 테이블로 접근
3. 페이지 테이블에서 해당 페이지가 어느 프레임에 저장되었는지 찾는다.
   - 물리 메모리에 있다면 바로 접근하고, 스왑 영역에 있다면 스왑 영역으로
4. 물리 메모리에 있는 프레임의 처음 위치에서 D만큼 떨어진 곳에 접근하여 데이터를 읽거나 씀

- `VA`=가상 주소, `S`=세그먼트 번호, `P`=페이지 번호, `D`=페이지의 처음 위치에서 해당 주소까지의 거리



## 5. 입출력 시스템과 디스크

### 입출력 시스템

#### 입출력 제어기

- 다양한 주변장치의 입출력을 대행하고 여러 채널에서 온 데이터를 메모리로 옮기는 역할을 합니다. 입출력 제어기는 메인버스와 입출력 버스라는 2개의 채널을 가집니다. 즉 CPU에서 입출력 요청이 오면 입출력 제어기가 입출력장치로부터 데이터를 직접 송수신합니다. 이를 통해 느린 입출력장치로 인한 CPU와 메모리의 작업이 느려지는 것을 막을 수 있어 전체 작업 효율이 향상됩니다.



#### 채널 선택기

- 고속 입출력 버스와 저속 입출력 버스 사이의 데이터 전송을 관리합니다. 여러 채널에서 전송된 데이터 중 어떤 것을 메모리로 보낼지 결정하거나, DMA 제어기가 메모리에서 데이터를 가져오면 적당한 채널로 전송합니다.  
  - 고속 입출력 버스: 고속 저장장치인 하드디스크, 랜카드 등 연결
  - 저속 입출력 장치: 키보드, 마우스, 스캐너 등 연결
    - 같은 입출력 버스를 공유하면 전체 입출력 속도가 떨어지므로 분리하여 운영



#### 직접 메모리 접근(DMA; Direct Memory Access)

- CPU의 도움이 없이도 메모리에 접근할 수 있도록 입출력 제어기에 부여된 권한입니다. 입출력 제어기에는 직접 메모리 접근을 위한 DMA 제어기가 있습니다.



#### 메모리 맵 입출력(Memory Mapped I/O)

- 메인메모리의 주소 공간 중 일부를 DMA 제어기에 할당하여 작업 공간이 겹치는 것을 막는 기법

<hr>



### 디스크[개요]

#### 하드디스크의 구조

- 플래터: 표면에 자성체가 발려 있어 자성을 이용하여 N극(0)과 S(1)의 데이터를 저장한다. 일정한 속도로 회전하고 있으며 위아래 표면을 모두 이용 가능하다.
- 섹터: 하드디스크의 가장 작은 저장 단위
- 블록: 데이터를 전송하는 논리적인 저장 단위 중 가장 작은 단위이며 여러 개의 섹터로 구성됨
  - 운영체제 입장에서는 하드디스크에 데이터를 보내거나 받을 때 가장 작은 저장 단위임
- 트랙: 플래터에서 회전축을 중심으로 데이터가 기록되는 동심원(섹터의 집합이 됨)
- 실린더: 여러 개의 플래터에 있는 같은 트랙의 집합
- 헤드: 데이터를 읽거나 쓸 때 사용되며 헤더의 수는 데이터가 저장되는 플래터의 표면의 수와 동일하다. 디스크 암에 붙어 있으며 플래터가 회전할 때 발생하는 약바람으로 약간 떠 있다.
  - 파킹: 컴퓨터가 종료될 때 플래터에 흠집을 내지 않도록 헤더를 플래터의 맨 바깥 쪽으로 이동하는 것



#### CD

- 하드디스크와 마찬가지로 트랙과 섹터로 구성되며, 수평으로 움직이는 헤드가 트랙 사이를 움직이며 데이터를 읽는다. 표면에 미세한 홈이 존재하는데 헤드에서 발사된 레이저가 홈에 들어가 반사되지 않으면 0, 반사되면 1로 인식하는 방식이다.



#### 하드디스크와 CD의 차이

- 회전 방식
  - 각속도 일정 방식의 회전: 하드디스크의 플래터는 항상 일정한 속도로 회전
    - 바깥쪽 트랙의 속도가 안쪽보다 빠름
  - 선속도 일정 방식의 회전: CD는 어느 트랙에서나 단위 시간 당 이동 속도가 같음
    - 헤드가 바깥쪽 트랙으로 이동할수록 회전 속도가 느려짐

- 섹터의 크기
  - 각속도 일정 방식의 섹터: 하드디스크는 트랙마다 속도가 다르므로 섹터의 크기도 다름
    - 바깥쪽 트랙일수록 섹터의 크기가 크고 공간 낭비가 생김
  - 선속도 일정 방식의 섹터: CD는 트랙의 속도가 같으므로 섹터의 크기도 같음
    - 바깥쪽 트랙일수록 섹터가 많지만 소음이 발생함

- 데이터를 쌓는 방식
  - 하드디스크와는 달리 CD는 안쪽부터 채워지는데, 사용자가 보통 바깥쪽을 만지기 때문



#### 데이터 전송 시간

- 데이터 전송 시간 = 탐색 시간 + 회전 지연 시간 + 전송 시간
  - 탐색 시간: 헤드가 섹터가 있는 트랙까지 이동하는 시간
    - 시간을 늘리는 주 요인으로 디스크 스케줄링 기법을 통해 최소화함
  - 회전 지연 시간: 원하는 섹터를 만날 때까지 회전하는 시간
  - 전송 시간: 섹터에 있는 데이터를 읽어 전송하는 시간



#### 파티션과 포매팅

- 파티션: 디스크를 논리적으로 분할하는 작업
- 포매팅: 디스크에 파일 시스템을 탑재하고 디스크 표면을 초기화하여 사용할 수 있는 형태로 만드는 작업
  - 빈 저장장치에 파일 테이블을 탑재하는 것
  - 느린 포매팅: 위의 설명한 것
  - 빠른 포매팅: 데이터는 그대로 둔 채 파일 테이블만을 초기화하는 것



#### DAS(Direct Attached Storage)

- 서버와 컴퓨터에 직접 연결되는 저장장치를 의미합니다. 직접 연결되므로 속도가 빠르지만 다른 운영체제라 파일 시스템이 다른 경우 사용할 수 없습니다. 또한 사용자가 데이터 관리나 백업을 직접 해야 하는 번거로움도 있습니다.



#### NAS(Network Attached Storage)

- 기존의 저장장치를 LAN이나 WAN(Wide Area Network)로 연결하여 사용하는 방식입니다. 데이터의 중복을 회피하면서 확장성과 유연성이 뛰어납니다. 하지만 DAS보다 속도가 느리고 파일 시스템을 공유하므로 보안에 비교적 취약합니다.



#### SAN(Storage Area Network)

- NAS가 저장장치에 네트워크 인터페이스를 부착한 형태라면, SAN은 데이터 서버, 백업 서버, RAID 등의 장치를 네트워크로 묶고 데이터 접근을 위한 서버를 두는 형태입니다. 여러 장치를 묶었으므로 다양한 서비스를 제공할 수 있습니다. 데이터 공유, 백업, 보안 등이 서버에서 자동으로 이루어집니다. 하지만 구축 비용에 많이 듭니다.

<hr>

### 디스크[스케줄링]

#### 디스크 스케줄링 목표

- 디스크의 전송 시간에 가장 큰 영향을 미치는 탐색 시간을 최소화하기 위한 스케줄링입니다.



#### 디스크 스케줄링

- FCFS: 요청이 들어온 트랙 순서대로 서비스
- SSTF: 현재 헤드가 있는 위치에서 가장 가까운 트랙부터 서비스(거리가 같다면 먼저 요청한 것부터)
  - 성능은 좋으나 가장 바깥쪽의 트랙은 서비스를 받을 확률이 낮아 아사 현상이 발생할 수 있음(공평성 위배)
- 블록 SSTF: 큐에 있는 트랙의 요청을 일정한 블록 형태로 묶고, 해당 블록 내에서 가장 가까운 트랙부터 서비스
  - SSTF의 공평성 위배를 완화하기 위해 에이징을 사용한 것이지만 FCFS보다 성능이 안좋음
- SCAN(엘리베이터 기법): 헤드가 한 뱡향으로만 움직이면서 서비스(무조건 맨 마지막 트랙까지 감)
  - 동일한 트랙이나 실린더 요청이 연속 발생하면 헤드가 제자리에 머물러 바깥쪽 요청은 아사 현상
  - SSTF보다 공평성은 덜 위배하나 바깥쪽 트랙의 방문 횟수는 공평하지 못함

- C-SCAN: 헤드가 한쪽 방향으로 움직일 때는 요청받은 트랙을 서비스하고 반대 방향으로 돌아올 때는 그냥 끝까지 이동
  - 모든 트랙의 방문 횟수가 동일하나 작업 없이 이동하는 것은 비효율적
  - 동일한 트랙이나 실린더 요청이 발생하면 SCAN이 겪는 문제를 똑같이 겪음
- LOOK: SCAN 디스크 스케줄링의 불필요 부분을 제거하여 효율을 높임(무조건 맨 마지막 트랙까지 가던 부분)
- C-LOOK: C-SCAN의 LOOK 버전
- SLTF: 드럼을 사용하는 일부 하드디스크(헤더가 고정된 경우)에서 사용하는 방식

<hr>



### RAID

#### RAID(Redundant Array of Independent Disk)

동일한 규격의 여러 개의 디스크를 묶어 하나의 디스크처럼 사용하는 기술입니다. 이렇게 묶은 디스크를 통해 자동으로 백업하거나 장애가 발생하면 복구하는 시스템입니다.



#### RAID 0(스트라이핑)

- 병렬로 연결된 여러 개의 디스크에 데이터를 동시에 입출력할 수 있도록 구성된 것입니다. 이를 통해 일반 시스템보다 훨씬 빠르게 입출력이 가능합니다. 하지만 장애 시 복구하는 기능이 없기 때문에 장애 시 데이터를 잃게됩니다.



#### RAID 1(미러링)

- 하나의 데이터를 2개의 디스크에 나누어 저장하여 장애 시 백업 디스크로 활용합니다. 순수한 백업 시스템으로 데이터가 똑같이 여러 디스크에 복사되어 미러링이라 부릅니다. 같은 내용을 두 번 저장하는 방식때문에 속도가 느려질 수 있습니다.



#### RAID 2

- 오류 검출 기능이 없는 디스크에 대해 오류 교정 코드(ECC)를 따로 관리하고, 오류가 발생하면 해당 코드를 통해 디스크를 복구합니다. 일반적인 데이터 저장 단위는 블록이나 RAID 2에서는 비트 단위로 저장합니다. 이 비트별로 오류 교정 코드를 만들어 별도의 디스크에 저장되는 방식입니다.
  - RAID 2는 n개의 디스크에 대해 오류 교정 코드를 저장하기 위해 n-1개의 추가 디스크를 필요로 하여 RAID 1보다 작은 저장 공간을 요구하나 오류 교정 코드 계산에 시간이 오래 걸려 잘 사용하지 않음



#### RAID 10

- RAID 1을 RAID 0으로 결합하여 미러링과 빠른 데이터 전송이 가능한 구조입니다.
  - RAID01의 경우 장애를 복구하기 위해 모든 디스크를 중지해야 하지만 RAID10은 일부 디스크만 중지함



#### RAID 3

- 오류 검출 코드인 패리티 비트를 사용하여 데이터를 복구합니다. 1의 개수를 짝수개로 만드는 짝수 패리티 비트와 홀수 개로 만드는 홀수 패리티 비트를 사용합니다. 즉 해당 패리티 비트와 오류가 발생한 디스크를 제외한 나머지 디스크의 1의 개수를 근거로 복구하는 것입니다.
  - N-way 패리티 비트 방식: RAID 3는 섹터 단위로 저장하는데, 이 경우 어떤 섹터에 오류가 있는지 알 수 없습니다. 따라서 오류 검출에 사용하는 패리티 비트를 여러 섹터끼리 묶어 구성하여 오류가 없는 섹터를 이용하여 오류가 있는 섹터의 데이터를 복구하는 방법입니다.



#### RAID 4

- RAID3과 같은 방식이지만 처리하는 데이터가 블록 방식입니다. RAID 3의 경우 데이터를 읽거나 쓸 때 패리티 비트를 구성하기 위해 모든 디스크가 동작해야 한다. 하지만 RAID 4는 데이터를 하나의 디스크에 블록 단위로 저장하고 패리티 비트를 블록과 연결하여 구성하여 데이터가 저장되는 디스크와 패리티 비트가 저장되는 딧크만 동작한다.
  - 모든 패리티 비트가 하나의 디스크에 저장되므로 입출력이 일어날 때마다 패리티 비트 디스크에 데이터가 저장되어 병목 현상이 발생함
  - 패리티 비트가 발생한 디스크와 다른 디스크가 동시에 장애 시 복구가 안됨



#### RAID 5

- RAID 4의 패리티 비트를 여러 디스크의 분산하여 구성하여 병목 현상을 해결한 구조입니다. 또한 패리티 비트를 해당 데이터가 없는 디스크에 보관하여 한 디스크의 장애가 발생해도 다른 디스크에 있는 패리티 비트를 이용하여 복구할 수 있습니다.



#### RAID 6

- RAID 5와 같은 방식이나 패리티 비트를 2개씩 저장하여 디스크 2개가 동시에 장애가 발생한 상황에 대처할 수 있습니다.
  - RAID 5보다 계산량이 많고 저장 공간을 더 사용



#### RAID 50과 RAID 60

- RAID 50은 RAID 5로 묶은 두 쌍을 다시 RAID 0으로 묶은 것
- RAID 60은 RAID 6으로 묶은 두 쌍을 다시 RAID 0으로 묶은 것
  - 결국 둘 모두 RAID 0으로 묶어 성능을 높이는 방식

<hr>

### 파일 시스템

#### 파일 시스템

- 파일을 보관하고 관리하는 파일 관리자를 두어 저장장치의 전체 관리를 맡기는 시스템입니다. 파일 관리자는 사용자 요청에 따라 파일을 저장하거나 파일의 내용을 읽습니다. 이를 통해 사용자가 저장장치 내부에 직접 접근하여 문제를 일으키는 것을 막습니다.



#### 파일 시스템의 기능

| 기능           | 설명                                                         |
| -------------- | ------------------------------------------------------------ |
| 파일 구성      | 사용자 요구에 따라 파일과 디렉터리를 만듬                    |
| 파일 관리      | 파일 생성, 수정, 삭제 등의 관리를 하며, 수시로 조각 모음을 하여 파일의 접근 속도를 높임 |
| 접근 권한 관리 | 다른 사용자로부터 파일을 보호하기 위해 접근 권한을 관리      |
| 접근 방법 제공 | 파일을 읽고 쓰고 실행할 수 있는 접근 방법을 제공             |
| 무결성 보장    | 파일의 내용이 손상되지 않도록 무결성을 보장                  |
| 백업과 복구    | 사고로부터 파일을 보호하기 위해 백업과 복구 작업을 진행      |
| 암호화         | 파일을 암호화하여 악의적인 접근으로 부터 파일을 보호         |



#### 파일의 분류

- 실행 파일: 운영체제가 메모리로 가져와 CPU를 이용하여 작업을 하는 파일
- 데이터 파일: 실행 파일이 작업하는 데 필요한 데이터를 모아놓은 파일



#### 순차 파일(Sequential File)

- 레코드를 논리적인 처리 순서에 따라 연속된 물리적 저장공간에 기록하는 것입니다. 파일의 레코드들이 순차적으로 기록되어 판독할 때도 순차적으로 접근하기 때문에 순차 접근 방식(SAM; Sequential Access Mothod)이라고도 합니다.
  - 장점
    - 순서대로 기록되므로 저장 공간에 낭비가 없음
    - 구조가 단순하여 여러 저장장치에서 활용 가능
    - 순서대로 읽거나 저장할 때 매우 빠름
  - 단점
    - 파일에 새로운 데이터를 삽입하거나 삭제할 때 시간이 오래 걸림
    - 특정 데이터로 이동할 때 순서대로 움직여야 하므로 검색에 적합하지 않음



#### 색인 순차 파일(Indexed Sequential File)

- 색인(인덱스)을 이용한 순차적인 접근 방법을 제공하여 색인 순차 접근 방식(ISAM; Index Sequential Access Method)이라고도 합니다. 각 레코드를 키 값 순으로 논리적으로 저장하고, 시스템은 각 레코드의 실제 주소가 저장된 색인을 관리합니다.
  - 장점
    - 순차 접근과 임의 접근이 가능
    - 효율적인 검색이 가능하고 삭제, 삽입, 갱신이 용이
  - 단점
    - 색인 영역이나 오버플로 영역을 설정해야 하므로 저장 공간이 필요
    - 색인을 이용하여 참조하므로 직접 파일보다 느림



#### 직접 파일(Direct File)

- 저장하려는 데이터의 특정 값에 어떤 관계를 정의하여 물리적인 주소로 바로 변환하는 구조로 직접 접근 방식(DAM; Direct Access Method)이라고도 합니다. 레코드에 특정 기준으로 키가 할당되는데, 해싱 함수(Hashing Function)를 이용합니다.
  - 장점
    - 해싱 함수로 주소를 변환하므로 데이터 접근이 매우 빠름
    - 접근 및 기록의 순서에 제약이 없음
  - 단점
    - 전체 데이터가 고르게 저장될 수 있는 해싱 함수를 찾아야 함
    - 적절한 해싱 함수를 찾아도 데이터가 들쑥날쑥 저장되므로 저장장치의 효율이 떨어짐

<hr>



### 디렉터리

#### 디렉터리

- 관련 있는 파일을 하나로 모아놓은 곳입니다. 디렉터리는 여러 층으로 구성할 수 있어 하나의 디렉터리에는 여러 개의 파일과 자식 디렉터리가 존재할 수 있습니다.



#### 절대 경로와 상대 경로

- 절대 경로: 최초의 시작점으로 경유한 경로를 전부 기입하여 파일의 위치를 표시하는 방식
- 상대 경로: 현재 있는 위치를 기준으로 파일의 위치를 표시하는 방식



#### 마운트

- 유닉스에서 여러 개의 파티션을 통합하는 명령어입니다. 물리적인 장치 또는 파티션을 특정한 위치(대부분 디렉터리)에 연결시켜주는 과정을 의미합니다.



#### 연속 할당과 불연속 할당

- 연속 할당: 파일을 구성하는 데이터를 디스크상에 연속적으로 배열하는 간단한 방식
  - 파일을 저장하고 삭제하다 보면 빈 공간이 생기는데, 디스크의 남은 공간 중 파일의 크기와 맞는 연속된 공간이 없으면 연속 할당이 불가능하므로 안쓰임
- 불연속 할당: 비어 있는 블록에 데이터를 분산하여 저장하고 이에 관한 정보를 파일 시스템이 관리하는 방식
  - 연결 할당과 인덱스 할당이 있음



#### 연결 할당과 인덱스 할당

- 연결 할당: 파일에 속한 데이터를 연결 리스트로 관리하는 방식입니다. 파일 테이블에는 시작 블록에 대한 정보만 저장하고, 나머지 데이터는 시작 블록부터 연결하여 저장합니다. 이때 파일의 맨 끝에는 링크 대신 널을 삽입합니다.
  - 구현은 간편하나 최대 할당 크기가 디스크 용량의 크기로 제한됨(FAT16 => 32GB, FAT32 => 8TB)
- 인덱스 할당: 테이블의 블록 포인터가 데이터 블록을 연결하는 것이 아니라, 데이터의 인덱스를 담고 있는 인덱스 블록을 연결합니다. 인덱스 블록은 실제 데이터의 위치에 관한 정보를 순서대로 보관하며, 파일의 끝은 -1로 알립니다.
  - 만약 테이블이 꽉 차서 더 이상 데이터를 연결할 수 없는 경우 간접 인덱스 블록을 만들어 테이블을 무한히 확장합니다.



#### 빈 공간 리스트

- 빈 공간을 효율적으로 관리하기 위해 파일 시스템이 빈 블록의 정보만을 모아놓은 공간입니다. 빈 공간 리스트에 삽입되는 블록에 있는 데이터를 지우지 않고 삽입한 뒤 덮어써서 속도를 높입니다. 또한 디스크에 먼저 들어온 블록부터 할당하여 특정 블록만 사용되는 것을 방지합니다.





## 99. 여러 용어 및 법칙

### 법칙

#### 무어의 법칙

- 고든 무어가 주장한 것으로, CPU의 속도가 24개월마다 2배 빨라진다는 법칙



#### 암달의 법칙

- 컴퓨터 시스템의 일부를 개선할 때 전체 시스템에 미치는 영향과 관계를 수식으로 나타낸 법칙